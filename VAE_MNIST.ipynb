{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPKPWNwWSTvoVjtPRF+w2Iu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chris-william0829/vae-mnist/blob/main/VAE_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "import os.path"
      ],
      "metadata": {
        "id": "-8XNPEcYfThC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# VAE模型定义\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
        "        super(VAE, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.latent_dim = latent_dim\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, latent_dim * 2)\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(latent_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, input_dim),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.encoder(x)\n",
        "        mu, logvar = h[:, :latent_dim], h[:, latent_dim:]\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        return self.decoder(z), mu, logvar"
      ],
      "metadata": {
        "id": "uuVIOrJvfVSt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 损失函数\n",
        "def loss_function(recon_x, x, mu, logvar):\n",
        "    #BCE = nn.functional.binary_cross_entropy(recon_x, x, reduction='sum')\n",
        "    BCE = nn.functional.mse_loss(recon_x, x, reduction='sum')\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    return BCE + KLD"
      ],
      "metadata": {
        "id": "xte3zfHBfX8f"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 超参数设置\n",
        "batch_size = 128\n",
        "epochs = 10\n",
        "learning_rate = 1e-3\n",
        "input_dim = 784\n",
        "hidden_dim = 400\n",
        "latent_dim = 20"
      ],
      "metadata": {
        "id": "3e0boM3ufala"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 数据加载\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Lambda(lambda x: x.view(-1))])\n",
        "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST('./data', train=False, download=True, transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "r9rJ-QJJfe5K"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 模型、优化器初始化\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = VAE(input_dim,hidden_dim,latent_dim).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "gR74MdWdfgxC"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# VAE训练\n",
        "if os.path.exists('vae.pth'):\n",
        "    model.load_state_dict(torch.load('vae.pth'))\n",
        "else:\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "      train_loss = 0\n",
        "      for batch_idx, (data, _) in enumerate(train_loader):\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        recon_batch, mu, logvar = model(data)\n",
        "        loss = loss_function(recon_batch, data, mu, logvar)\n",
        "        loss.backward()\n",
        "        train_loss += loss.item()\n",
        "        optimizer.step()\n",
        "      print(f\"Epoch {epoch + 1}/{epochs}, Loss: {train_loss / len(train_loader.dataset)}\")\n",
        "    torch.save(model.state_dict(), './vae.pth')"
      ],
      "metadata": {
        "id": "l_1fs1Q-gCTL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "890f6c46-96ce-4a4f-962a-9d832b3c6a45"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 45.714595186360675\n",
            "Epoch 2/10, Loss: 35.155865209960936\n",
            "Epoch 3/10, Loss: 33.19220285644531\n",
            "Epoch 4/10, Loss: 32.29306981608073\n",
            "Epoch 5/10, Loss: 31.72323212483724\n",
            "Epoch 6/10, Loss: 31.379750838216147\n",
            "Epoch 7/10, Loss: 31.073921618652342\n",
            "Epoch 8/10, Loss: 30.854611385091147\n",
            "Epoch 9/10, Loss: 30.673968111165365\n",
            "Epoch 10/10, Loss: 30.51398776855469\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 提取训练集隐变量\n",
        "model.eval()\n",
        "train_hidden_vars = []\n",
        "train_labels = []\n",
        "for data, target in train_loader:\n",
        "    data = data.to(device)\n",
        "    with torch.no_grad():\n",
        "        h = model.encoder(data)\n",
        "        mu, _ = h[:, :latent_dim], h[:, latent_dim:]\n",
        "    train_hidden_vars.append(mu.cpu().numpy())\n",
        "    train_labels.append(target.numpy())\n",
        "\n",
        "train_hidden_vars = np.concatenate(train_hidden_vars, axis=0)\n",
        "train_labels = np.concatenate(train_labels, axis=0)"
      ],
      "metadata": {
        "id": "bBp-v5KVfoiC"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 提取测试集隐变量\n",
        "test_hidden_vars = []\n",
        "test_labels = []\n",
        "for data, target in test_loader:\n",
        "    data = data.to(device)\n",
        "    with torch.no_grad():\n",
        "        h = model.encoder(data)\n",
        "        mu, _ = h[:, :latent_dim], h[:, latent_dim:]\n",
        "    test_hidden_vars.append(mu.cpu().numpy())\n",
        "    test_labels.append(target.numpy())\n",
        "\n",
        "test_hidden_vars = np.concatenate(test_hidden_vars, axis=0)\n",
        "test_labels = np.concatenate(test_labels, axis=0)"
      ],
      "metadata": {
        "id": "1X2BbbYRiZ8b"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 使用SVC进行分类\n",
        "svc = SVC()\n",
        "svc.fit(train_hidden_vars, train_labels)"
      ],
      "metadata": {
        "id": "jIXyJeKJfuOe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "outputId": "68a3650e-59b8-4609-8650-04ea39b2ccd1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 计算训练集准确率\n",
        "train_preds = svc.predict(train_hidden_vars)\n",
        "train_acc = accuracy_score(train_labels, train_preds)\n",
        "print(f\"Training accuracy: {train_acc}\")"
      ],
      "metadata": {
        "id": "8Ya1pSFDfukR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebc89767-97d1-4b6d-d6fe-f3f66d9ea96d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 0.9832833333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 计算测试集准确率\n",
        "test_preds = svc.predict(test_hidden_vars)\n",
        "test_acc = accuracy_score(test_labels, test_preds)\n",
        "print(f\"Test accuracy: {test_acc}\")"
      ],
      "metadata": {
        "id": "YjpdbTEAfwaj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "091a55ac-11aa-4203-d8a6-76178a31146b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.9771\n"
          ]
        }
      ]
    }
  ]
}